{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"./data/elucidata_ai_challenge_data.h5\")\n",
    "\n",
    "train_images = f['images/Train'] # 6 images with id's like S_1,S_2 to S_6\n",
    "test_image = f['images/Test'] # 1 image with id S_7\n",
    "\n",
    "train_spots = f['spots/Train'] # this contains spot data for each 6 ids first 2 columns are x and y and column 3 to 37 are cell abundance\n",
    "test_spot = f['spots/Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"S_1\": shape (2000, 1974, 3), type \"<f4\">\n",
      "<HDF5 dataset \"S_2\": shape (2000, 1988, 3), type \"<f4\">\n",
      "<HDF5 dataset \"S_3\": shape (2000, 1966, 3), type \"<f4\">\n",
      "<HDF5 dataset \"S_4\": shape (2000, 1979, 3), type \"<f4\">\n",
      "<HDF5 dataset \"S_5\": shape (1985, 2000, 3), type \"<f4\">\n",
      "<HDF5 dataset \"S_6\": shape (2000, 1930, 3), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "for key in train_images.keys():\n",
    "    print(train_images[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(h5_file, patch_size=128, val_ratio=0.1):\n",
    "    images = h5_file['images/Train']\n",
    "    spots = h5_file['spots/Train']\n",
    "\n",
    "    train_patches = []\n",
    "    train_targets = []\n",
    "    val_patches = []\n",
    "    val_targets = []\n",
    "\n",
    "    half = patch_size // 2\n",
    "    for slide_id in images.keys():\n",
    "        img = np.array(images[slide_id])  # shape: (H, W, 3)\n",
    "        # print(img.shape)\n",
    "\n",
    "        # Fix: handle structured array\n",
    "        spot_data = pd.DataFrame(spots[slide_id][()])\n",
    "\n",
    "        coords = spot_data.iloc[:, :2].astype(int).values  # x, y\n",
    "        targets = spot_data.iloc[:, 2:].values  # shape: (num_spots, 35)\n",
    "\n",
    "        num_spots = coords.shape[0]\n",
    "        indices = np.arange(num_spots)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        split_idx = int((1 - val_ratio) * num_spots)\n",
    "        train_idx, val_idx = indices[:split_idx], indices[split_idx:]\n",
    "\n",
    "        # 以 spot 坐标为中心，截取一个边长为 patch 的正方形图片。如果因为 spot 太靠近边缘导致截取不出正方形就抛弃这个样本。\n",
    "        for idx in train_idx:\n",
    "            x, y = coords[idx]\n",
    "            if x - half < 0 or y - half < 0 or x + half > img.shape[1] or y + half > img.shape[0]:\n",
    "                continue\n",
    "            patch = img[y - half:y + half, x - half:x + half]\n",
    "            if patch.shape[:2] == (patch_size, patch_size):\n",
    "                train_patches.append(patch)\n",
    "                train_targets.append(targets[idx])\n",
    "        for idx in val_idx:\n",
    "            x, y = coords[idx]\n",
    "            if x - half < 0 or y - half < 0 or x + half > img.shape[1] or y + half > img.shape[0]:\n",
    "                continue\n",
    "            patch = img[y - half:y + half, x - half:x + half]\n",
    "            if patch.shape[:2] == (patch_size, patch_size):\n",
    "                val_patches.append(patch)\n",
    "                val_targets.append(targets[idx])\n",
    "\n",
    "    return (\n",
    "        np.array(train_patches), np.array(train_targets),\n",
    "        np.array(val_patches), np.array(val_targets)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train patches: (7513, 128, 128, 3)\n",
      "Train targets: (7513, 35)\n",
      "Val patches: (836, 128, 128, 3)\n",
      "Val targets: (836, 35)\n"
     ]
    }
   ],
   "source": [
    "train_patches, train_targets, val_patches, val_targets = extract_patches(f)\n",
    "\n",
    "print(\"Train patches:\", train_patches.shape)\n",
    "print(\"Train targets:\", train_targets.shape)\n",
    "print(\"Val patches:\", val_patches.shape)\n",
    "print(\"Val targets:\", val_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class SpotPatchDataset(Dataset):\n",
    "    def __init__(self, patches, targets):\n",
    "        self.patches = patches\n",
    "        self.targets = targets\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),  # Convert to [0,1] and shape [C,H,W]\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.patches[idx]\n",
    "        target = self.targets[idx]\n",
    "        image = self.transform(image)\n",
    "        target = torch.tensor(target, dtype=torch.float32)\n",
    "        return image, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = SpotPatchDataset(train_patches, train_targets)\n",
    "val_dataset = SpotPatchDataset(val_patches, val_targets)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class ResNetRegressor(nn.Module):\n",
    "    def __init__(self, output_dim=35):\n",
    "        super(ResNetRegressor, self).__init__()\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Replace final FC layer\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(in_features, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AI\\kaggle\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "e:\\AI\\kaggle\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\PilockHulmes/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44.7M/44.7M [00:16<00:00, 2.77MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = ResNetRegressor(output_dim=35)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Loss: MSE for regression\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    return running_loss / len(dataloader.dataset)\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    return running_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 0.7452 | Val Loss: 0.4794\n",
      "Epoch 2/5 | Train Loss: 0.4144 | Val Loss: 0.4325\n",
      "Epoch 3/5 | Train Loss: 0.2760 | Val Loss: 0.3907\n",
      "Epoch 4/5 | Train Loss: 0.2018 | Val Loss: 0.4086\n",
      "Epoch 5/5 | Train Loss: 0.1717 | Val Loss: 0.4143\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_test_patches(h5_file, patch_size=128):\n",
    "    test_img = np.array(h5_file['images/Test']['S_7'])\n",
    "    test_spot_data = pd.DataFrame(np.array(h5_file['spots/Test']['S_7']))  # shape: (num_spots, 37)\n",
    "    \n",
    "    coords = test_spot_data.iloc[:, :2].astype(int).values  # x, y\n",
    "    half = patch_size // 2\n",
    "\n",
    "    patches = []\n",
    "    valid_coords = []\n",
    "\n",
    "    for coord in coords:\n",
    "        x, y = coord\n",
    "        if x - half < 0 or y - half < 0 or x + half > test_img.shape[1] or y + half > test_img.shape[0]:\n",
    "            continue\n",
    "        patch = test_img[y - half:y + half, x - half:x + half]\n",
    "        if patch.shape[:2] == (patch_size, patch_size):\n",
    "            patches.append(patch)\n",
    "            valid_coords.append(coord)\n",
    "\n",
    "    return np.array(patches), np.array(valid_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patches, test_coords = extract_test_patches(f)\n",
    "test_patches_tensor = torch.tensor(test_patches).permute(0, 3, 1, 2).float()   # (N, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_patches_tensor), 32):\n",
    "        batch = test_patches_tensor[i:i+32].to(device)\n",
    "        outputs = model(batch).cpu().numpy()\n",
    "        predictions.append(outputs)\n",
    "\n",
    "predictions = np.vstack(predictions)  # shape: (num_valid_spots, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame(predictions, columns=[f'cell_type_{i+1}' for i in range(35)])\n",
    "df_preds.insert(0, 'ID', range(len(df_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>cell_type_1</th>\n",
       "      <th>cell_type_2</th>\n",
       "      <th>cell_type_3</th>\n",
       "      <th>cell_type_4</th>\n",
       "      <th>cell_type_5</th>\n",
       "      <th>cell_type_6</th>\n",
       "      <th>cell_type_7</th>\n",
       "      <th>cell_type_8</th>\n",
       "      <th>cell_type_9</th>\n",
       "      <th>...</th>\n",
       "      <th>cell_type_26</th>\n",
       "      <th>cell_type_27</th>\n",
       "      <th>cell_type_28</th>\n",
       "      <th>cell_type_29</th>\n",
       "      <th>cell_type_30</th>\n",
       "      <th>cell_type_31</th>\n",
       "      <th>cell_type_32</th>\n",
       "      <th>cell_type_33</th>\n",
       "      <th>cell_type_34</th>\n",
       "      <th>cell_type_35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.174584</td>\n",
       "      <td>0.027349</td>\n",
       "      <td>-0.012746</td>\n",
       "      <td>0.082535</td>\n",
       "      <td>-0.046270</td>\n",
       "      <td>0.104565</td>\n",
       "      <td>0.085526</td>\n",
       "      <td>-0.055208</td>\n",
       "      <td>0.126084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>0.075627</td>\n",
       "      <td>-0.070324</td>\n",
       "      <td>0.072997</td>\n",
       "      <td>0.129147</td>\n",
       "      <td>0.021696</td>\n",
       "      <td>-0.024244</td>\n",
       "      <td>0.125135</td>\n",
       "      <td>-0.027928</td>\n",
       "      <td>0.000338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.131282</td>\n",
       "      <td>0.161235</td>\n",
       "      <td>0.207157</td>\n",
       "      <td>-0.139339</td>\n",
       "      <td>0.741986</td>\n",
       "      <td>-0.073061</td>\n",
       "      <td>-0.050273</td>\n",
       "      <td>0.047330</td>\n",
       "      <td>0.052717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030605</td>\n",
       "      <td>-0.124524</td>\n",
       "      <td>-0.100443</td>\n",
       "      <td>0.130916</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.093736</td>\n",
       "      <td>-0.025264</td>\n",
       "      <td>0.086049</td>\n",
       "      <td>0.061811</td>\n",
       "      <td>-0.011804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.964469</td>\n",
       "      <td>0.155687</td>\n",
       "      <td>1.844579</td>\n",
       "      <td>1.257519</td>\n",
       "      <td>1.531961</td>\n",
       "      <td>0.041686</td>\n",
       "      <td>0.243872</td>\n",
       "      <td>-0.035342</td>\n",
       "      <td>0.029778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035841</td>\n",
       "      <td>0.066327</td>\n",
       "      <td>0.093249</td>\n",
       "      <td>0.089618</td>\n",
       "      <td>-0.089410</td>\n",
       "      <td>0.166974</td>\n",
       "      <td>0.200569</td>\n",
       "      <td>0.024088</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>0.164817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.477433</td>\n",
       "      <td>0.157950</td>\n",
       "      <td>1.775822</td>\n",
       "      <td>1.067452</td>\n",
       "      <td>1.162134</td>\n",
       "      <td>0.098915</td>\n",
       "      <td>0.172305</td>\n",
       "      <td>-0.066085</td>\n",
       "      <td>0.079294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044754</td>\n",
       "      <td>0.083666</td>\n",
       "      <td>0.097626</td>\n",
       "      <td>0.146031</td>\n",
       "      <td>-0.099052</td>\n",
       "      <td>0.214242</td>\n",
       "      <td>0.154818</td>\n",
       "      <td>0.085896</td>\n",
       "      <td>0.079986</td>\n",
       "      <td>0.194094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.746700</td>\n",
       "      <td>0.100708</td>\n",
       "      <td>0.503298</td>\n",
       "      <td>0.623538</td>\n",
       "      <td>0.811936</td>\n",
       "      <td>0.159962</td>\n",
       "      <td>0.149131</td>\n",
       "      <td>0.107832</td>\n",
       "      <td>-0.126790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047254</td>\n",
       "      <td>-0.021375</td>\n",
       "      <td>-0.203817</td>\n",
       "      <td>0.077706</td>\n",
       "      <td>-0.109591</td>\n",
       "      <td>0.190179</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.030271</td>\n",
       "      <td>-0.083986</td>\n",
       "      <td>0.104075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>2083</td>\n",
       "      <td>1.314880</td>\n",
       "      <td>0.171256</td>\n",
       "      <td>0.614562</td>\n",
       "      <td>0.702651</td>\n",
       "      <td>2.039878</td>\n",
       "      <td>0.156576</td>\n",
       "      <td>0.113571</td>\n",
       "      <td>0.032434</td>\n",
       "      <td>0.294636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113106</td>\n",
       "      <td>0.161888</td>\n",
       "      <td>0.025886</td>\n",
       "      <td>0.246883</td>\n",
       "      <td>-0.021899</td>\n",
       "      <td>0.200136</td>\n",
       "      <td>0.184720</td>\n",
       "      <td>0.185973</td>\n",
       "      <td>-0.032186</td>\n",
       "      <td>0.168197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>2084</td>\n",
       "      <td>0.577924</td>\n",
       "      <td>-0.025309</td>\n",
       "      <td>0.464563</td>\n",
       "      <td>0.488105</td>\n",
       "      <td>0.778466</td>\n",
       "      <td>0.204367</td>\n",
       "      <td>0.066787</td>\n",
       "      <td>-0.063337</td>\n",
       "      <td>-0.016045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042081</td>\n",
       "      <td>0.089921</td>\n",
       "      <td>-0.107632</td>\n",
       "      <td>-0.018493</td>\n",
       "      <td>-0.064729</td>\n",
       "      <td>0.079831</td>\n",
       "      <td>-0.102010</td>\n",
       "      <td>0.129238</td>\n",
       "      <td>-0.030160</td>\n",
       "      <td>-0.030514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>2085</td>\n",
       "      <td>1.046885</td>\n",
       "      <td>0.065520</td>\n",
       "      <td>0.538273</td>\n",
       "      <td>0.617251</td>\n",
       "      <td>0.911059</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>0.082960</td>\n",
       "      <td>0.132783</td>\n",
       "      <td>0.087148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104870</td>\n",
       "      <td>0.137216</td>\n",
       "      <td>-0.195490</td>\n",
       "      <td>-0.108503</td>\n",
       "      <td>-0.005482</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>-0.064646</td>\n",
       "      <td>-0.006508</td>\n",
       "      <td>0.110449</td>\n",
       "      <td>0.065237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>2086</td>\n",
       "      <td>0.144632</td>\n",
       "      <td>0.162647</td>\n",
       "      <td>0.167482</td>\n",
       "      <td>0.027493</td>\n",
       "      <td>0.422153</td>\n",
       "      <td>0.129378</td>\n",
       "      <td>0.059011</td>\n",
       "      <td>0.061215</td>\n",
       "      <td>-0.125368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031321</td>\n",
       "      <td>-0.196345</td>\n",
       "      <td>0.007433</td>\n",
       "      <td>0.137486</td>\n",
       "      <td>-0.016016</td>\n",
       "      <td>0.048250</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>0.216284</td>\n",
       "      <td>0.101883</td>\n",
       "      <td>-0.070533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>2087</td>\n",
       "      <td>1.545194</td>\n",
       "      <td>0.285426</td>\n",
       "      <td>1.119763</td>\n",
       "      <td>0.980481</td>\n",
       "      <td>3.343047</td>\n",
       "      <td>0.150804</td>\n",
       "      <td>0.096662</td>\n",
       "      <td>-0.184391</td>\n",
       "      <td>0.830136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028246</td>\n",
       "      <td>0.339275</td>\n",
       "      <td>-0.281596</td>\n",
       "      <td>0.423674</td>\n",
       "      <td>-0.139707</td>\n",
       "      <td>0.113651</td>\n",
       "      <td>-0.001441</td>\n",
       "      <td>0.129234</td>\n",
       "      <td>0.063926</td>\n",
       "      <td>0.038017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2088 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  cell_type_1  cell_type_2  cell_type_3  cell_type_4  cell_type_5  \\\n",
       "0        0    -0.174584     0.027349    -0.012746     0.082535    -0.046270   \n",
       "1        1     0.131282     0.161235     0.207157    -0.139339     0.741986   \n",
       "2        2     2.964469     0.155687     1.844579     1.257519     1.531961   \n",
       "3        3     2.477433     0.157950     1.775822     1.067452     1.162134   \n",
       "4        4     0.746700     0.100708     0.503298     0.623538     0.811936   \n",
       "...    ...          ...          ...          ...          ...          ...   \n",
       "2083  2083     1.314880     0.171256     0.614562     0.702651     2.039878   \n",
       "2084  2084     0.577924    -0.025309     0.464563     0.488105     0.778466   \n",
       "2085  2085     1.046885     0.065520     0.538273     0.617251     0.911059   \n",
       "2086  2086     0.144632     0.162647     0.167482     0.027493     0.422153   \n",
       "2087  2087     1.545194     0.285426     1.119763     0.980481     3.343047   \n",
       "\n",
       "      cell_type_6  cell_type_7  cell_type_8  cell_type_9  ...  cell_type_26  \\\n",
       "0        0.104565     0.085526    -0.055208     0.126084  ...      0.006996   \n",
       "1       -0.073061    -0.050273     0.047330     0.052717  ...      0.030605   \n",
       "2        0.041686     0.243872    -0.035342     0.029778  ...      0.035841   \n",
       "3        0.098915     0.172305    -0.066085     0.079294  ...      0.044754   \n",
       "4        0.159962     0.149131     0.107832    -0.126790  ...      0.047254   \n",
       "...           ...          ...          ...          ...  ...           ...   \n",
       "2083     0.156576     0.113571     0.032434     0.294636  ...      0.113106   \n",
       "2084     0.204367     0.066787    -0.063337    -0.016045  ...      0.042081   \n",
       "2085     0.003176     0.082960     0.132783     0.087148  ...     -0.104870   \n",
       "2086     0.129378     0.059011     0.061215    -0.125368  ...      0.031321   \n",
       "2087     0.150804     0.096662    -0.184391     0.830136  ...      0.028246   \n",
       "\n",
       "      cell_type_27  cell_type_28  cell_type_29  cell_type_30  cell_type_31  \\\n",
       "0         0.075627     -0.070324      0.072997      0.129147      0.021696   \n",
       "1        -0.124524     -0.100443      0.130916      0.011940      0.093736   \n",
       "2         0.066327      0.093249      0.089618     -0.089410      0.166974   \n",
       "3         0.083666      0.097626      0.146031     -0.099052      0.214242   \n",
       "4        -0.021375     -0.203817      0.077706     -0.109591      0.190179   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2083      0.161888      0.025886      0.246883     -0.021899      0.200136   \n",
       "2084      0.089921     -0.107632     -0.018493     -0.064729      0.079831   \n",
       "2085      0.137216     -0.195490     -0.108503     -0.005482      0.063600   \n",
       "2086     -0.196345      0.007433      0.137486     -0.016016      0.048250   \n",
       "2087      0.339275     -0.281596      0.423674     -0.139707      0.113651   \n",
       "\n",
       "      cell_type_32  cell_type_33  cell_type_34  cell_type_35  \n",
       "0        -0.024244      0.125135     -0.027928      0.000338  \n",
       "1        -0.025264      0.086049      0.061811     -0.011804  \n",
       "2         0.200569      0.024088      0.011976      0.164817  \n",
       "3         0.154818      0.085896      0.079986      0.194094  \n",
       "4         0.001684      0.030271     -0.083986      0.104075  \n",
       "...            ...           ...           ...           ...  \n",
       "2083      0.184720      0.185973     -0.032186      0.168197  \n",
       "2084     -0.102010      0.129238     -0.030160     -0.030514  \n",
       "2085     -0.064646     -0.006508      0.110449      0.065237  \n",
       "2086     -0.001363      0.216284      0.101883     -0.070533  \n",
       "2087     -0.001441      0.129234      0.063926      0.038017  \n",
       "\n",
       "[2088 rows x 36 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
